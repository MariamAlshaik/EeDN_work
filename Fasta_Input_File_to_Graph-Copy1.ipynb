{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New tasks:\n",
    "- make a function that read a fasta file from disk and yields (header, seq) pairs +\n",
    "- ex from:\n",
    ">AB003409.1/96-167\n",
    "GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comment\n",
    "CCAGUGGGUCCA\n",
    ">AB009835.1/1-71\n",
    "CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUU\n",
    "CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUU\n",
    "CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUU\n",
    "CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUU\n",
    "- yield:\n",
    "(AB003409.1/96-167, GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUCCCAGUGGGUCCA)\n",
    "(AB009835.1/1-71,CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUUCAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUUCAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUUCAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUacagugcCUU)\n",
    "\n",
    "- make a function that receives in input the list of sequences, and yields structure graphs +\n",
    "- make a function that receives a iterator over graphs and i,j and plots only graphs from num i to num j\n",
    "\n",
    "\n",
    "1. test if space or tab\n",
    "2. test if command (after a space or any latter exept 'aucg' or 'rnytkmswbdhvgu')\n",
    "3. test if new line without header then concatenate\n",
    "4. test if new line with header then new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import subprocess as sp\n",
    "from itertools import cycle\n",
    "import networkx as nx\n",
    "import re\n",
    "from eden.util import display\n",
    "\n",
    "class FastaToGraph(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def SequeceWrapper(self, path):\n",
    "        #path = \"/home/alsheikm/Work/EDeN_examples/fastaFiles/\"\n",
    "        seq = self._readFastaFile(path)\n",
    "        #eqs = self._removeCommands(seq)\n",
    "        print (\"path\", path)\n",
    "        return seqs\n",
    "    \n",
    "# read a fasta file separate the head and the sequence\n",
    "#    def _readFastaFile(self, file_name):\n",
    "    def _readFastaFile(self, path):\n",
    "#        print 'fastafile'\n",
    "#        path = \"/home/alsheikm/Work/EDeN_examples/fastaFiles/\"\n",
    "        head_start = '>'\n",
    "        head = []\n",
    "        seq = []\n",
    "        seq1 = []\n",
    "        #seq2 = []\n",
    "        #merge_seq =[]\n",
    "\n",
    "\n",
    "        for file in os.listdir(path):\n",
    "#            print (\"file:\", file)\n",
    "            #open file\n",
    "            read_file = open(os.path.join( path, file),'r')\n",
    "            \n",
    "\n",
    "            #seperate the head and the sequence\n",
    "            for line in read_file:\n",
    "                lines = list(line)\n",
    "                print (\"line\", line)\n",
    "                #print (\"lines\", lines)\n",
    "                if lines[0] == head_start:\n",
    "                    line = line.strip().split('\\n')\n",
    "                    head.append(line)\n",
    "                    \n",
    "                    print ('head', head)\n",
    "                #if lines[0] != head_start:\n",
    "#                    line = line.strip().split('\\n')\n",
    "#                    seq.insert(len(seq),line)\n",
    "                    #seq1.append(line)\n",
    "                else:\n",
    "                    seq1.append(line)\n",
    "                    #if lines[-1] == \"\\n\":\n",
    "                    print (\"last char\", lines[-1])\n",
    "                        # test the following lines if they are sequence complements\n",
    "                        #for line in fi:\n",
    "                        #while line\n",
    "                         #   print (\"line\", line)\n",
    "                            #if the next line is not a head write it in the same list\n",
    "                    line_iter = cycle(line)\n",
    "                    next_line = line_iter.next()\n",
    "                    next_lines = list(next_line)\n",
    "                    print (\"next_line\", next_line)\n",
    "                    if next_lines[0] != head_start:\n",
    "                        print (\"next_line[0]\", next_lines[0])\n",
    "\n",
    "                            #if lines[0] != head_start:\n",
    "                            #line = line.strip().split('\\n')\n",
    "                        seq1.append(line)\n",
    "                        print ('seq1',seq1)\n",
    "                        \n",
    "                            #else:\n",
    "                             #   head.append(line)\n",
    "                            #seq.append(seq1)\n",
    "                            #print ('merge', seq)\n",
    "                                       #line_iter = iter(line)\n",
    "                            #next_line = line_iter.next()\n",
    "                            #print (\"next_line\", next_line)\n",
    "                            #if next_line[0] != head_start:\n",
    "                                #seq += next_line\n",
    "            seq.extend(seq1)\n",
    "            print ('last_seq', seq)\n",
    "        return seq\n",
    "    \n",
    "    #read a line ignore string after the whitspace, tab and not (a,c,g,u)\n",
    "    def _removeCommands(self, seq):\n",
    "        #s = 'acugg eu ac af \\t r \\n ne'\n",
    "        #print s\n",
    "        new_seq = []\n",
    "        not_added = []\n",
    "        print (\"input seq1:\", seq)\n",
    "        seq = str(seq)\n",
    "        #print (\"string seq2:\", seq)\n",
    "        for i, letter in enumerate(seq):\n",
    "            print (\"letter:\", letter)\n",
    "            print (\"seq_remove:\",seq)\n",
    "            print '#######'\n",
    "            if letter == \"A\" or letter == \"C\" or letter == \"G\" or letter == \"U\":\n",
    "        #    if letter == {'a','c','g','u'}:\n",
    "                print ('letter:', letter)\n",
    "                letters = list(letter)\n",
    "                new_seq = new_seq + letters\n",
    "                    #new_s = new_s + letter\n",
    "                print ('new_seq:', new_seq)\n",
    "                print '******'\n",
    "            else:\n",
    "                if letter == \" \" or letter != \"A\" or letter != \"C\" or letter != \"G\" or letter != \"U\":\n",
    "                    letters = list(letter)\n",
    "                    not_added = not_added + letters\n",
    "                    print ('not_added:', not_added)\n",
    "                    print '-----'\n",
    "            \n",
    "            print (\"seq_remove:\",seq)        \n",
    "            print ('final not_added:', not_added)\n",
    "            print ('final new_seq:', new_seq)\n",
    "            seqs = ','.join(new_seq)\n",
    "            print ('returned seq1=', seqs)\n",
    "            seqs2 = list(new_seq)\n",
    "            print ('returned seq2=', seqs2)\n",
    "        \n",
    "        return seqs\n",
    "\n",
    "#generate the graph for each read sequence\n",
    "    def _makeFastaGraph(self, seq):\n",
    "        G = nx.Graph()\n",
    "        for j,sequence in enumerate(seq):\n",
    "    #        print ('j', j)\n",
    "            print (\"sequence\", sequence)\n",
    "            sequences = list(sequence)\n",
    "            for i,letter in enumerate(sequences):\n",
    "                G.add_node(i, label = sequences[i])\n",
    "                if i > 0:\n",
    "                    G.add_edge(i-1, i, label = 'x')\n",
    "            return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('line', '>AB003409.1/96-167\\n')\n",
      "('head', [['>AB003409.1/96-167']])\n",
      "('line', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'G')\n",
      "('next_line[0]', 'G')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n'])\n",
      "('line', 'CCAGUGGGUCCA\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'C')\n",
      "('next_line[0]', 'C')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n'])\n",
      "('line', '>AB009835.1/1-71\\n')\n",
      "('head', [['>AB003409.1/96-167'], ['>AB009835.1/1-71']])\n",
      "('line', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'C')\n",
      "('next_line[0]', 'C')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n'])\n",
      "('line', 'ACUUCUAAUGA\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'A')\n",
      "('next_line[0]', 'A')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n'])\n",
      "('last_seq', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n'])\n",
      "('line', '>AB003409.1/96-167\\n')\n",
      "('head', [['>AB003409.1/96-167'], ['>AB009835.1/1-71'], ['>AB003409.1/96-167']])\n",
      "('line', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'G')\n",
      "('next_line[0]', 'G')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n'])\n",
      "('line', 'CCAGUGGGUCCA\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'C')\n",
      "('next_line[0]', 'C')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n'])\n",
      "('line', '>AB009835.1/1-71\\n')\n",
      "('head', [['>AB003409.1/96-167'], ['>AB009835.1/1-71'], ['>AB003409.1/96-167'], ['>AB009835.1/1-71']])\n",
      "('line', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'C')\n",
      "('next_line[0]', 'C')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n'])\n",
      "('line', 'ACUUCUAAUGA\\n')\n",
      "('last char', '\\n')\n",
      "('next_line', 'A')\n",
      "('next_line[0]', 'A')\n",
      "('seq1', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n'])\n",
      "('last_seq', ['GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'GGGCCCAUAGCUCAGUGGUAGAGUGCCUCCUUUGCAAGGAGGAUGCCCUGGGUUCGAAUC comments\\n', 'CCAGUGGGUCCA\\n', 'CCAGUGGGUCCA\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'CAUUAGAUGACUGAAAGCAAGUACUGGUCUCUUAAACCAUUUAAUAGUAAAUUAGCACUU\\n', 'ACUUCUAAUGA\\n', 'ACUUCUAAUGA\\n'])\n",
      "('path', '/home/alsheikm/Work/EDeN_examples/fasta/')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3ecc17241deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastaToGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/home/alsheikm/Work/EDeN_examples/fasta/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mseqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequeceWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-016f0b085ff9>\u001b[0m in \u001b[0;36mSequeceWrapper\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#eqs = self._removeCommands(seq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"path\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mseqs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# read a fasta file separate the head and the sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'seqs' is not defined"
     ]
    }
   ],
   "source": [
    "#Read fasta files and separate sequences from the head of the sequence\n",
    "fgraph = FastaToGraph()\n",
    "path = \"/home/alsheikm/Work/EDeN_examples/fasta/\"\n",
    "seqs = fgraph.SequeceWrapper(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generating the graph\n",
    "for seq in seqs:\n",
    "    G = fgraph._makeFastaGraph(seq)\n",
    "    display.draw_graph(G, node_size=180, font_size=9, node_border=True, prog='neato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
